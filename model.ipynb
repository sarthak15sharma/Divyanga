{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87151 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Augmentation - Modifying the images of the training set so that the CNN Model does not overlearn the existing images as we will get new images in the test set \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, #for feature scaling\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "#Importing the training dataset\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/Train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37439 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test Set preprocessing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#Importing the test dataset\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/Test',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification, so 1 neuron and sigmoid activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 683329 (2.61 MB)\n",
      "Trainable params: 683329 (2.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Phatak\\Desktop\\Divyanga\\myenv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 152ms/step - accuracy: 0.7754 - loss: 0.4018 - val_accuracy: 0.6729 - val_loss: 1.0634\n",
      "Epoch 2/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 75ms/step - accuracy: 0.8363 - loss: 0.2750 - val_accuracy: 0.6952 - val_loss: 1.4928\n",
      "Epoch 3/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 77ms/step - accuracy: 0.8400 - loss: 0.2644 - val_accuracy: 0.6701 - val_loss: 1.1590\n",
      "Epoch 4/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 77ms/step - accuracy: 0.8415 - loss: 0.2614 - val_accuracy: 0.6951 - val_loss: 1.3324\n",
      "Epoch 5/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 77ms/step - accuracy: 0.8420 - loss: 0.2581 - val_accuracy: 0.6797 - val_loss: 1.9074\n",
      "Epoch 6/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 78ms/step - accuracy: 0.8418 - loss: 0.2572 - val_accuracy: 0.6837 - val_loss: 1.4137\n",
      "Epoch 7/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 75ms/step - accuracy: 0.8408 - loss: 0.2555 - val_accuracy: 0.6865 - val_loss: 2.1304\n",
      "Epoch 8/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 74ms/step - accuracy: 0.8386 - loss: 0.2563 - val_accuracy: 0.6862 - val_loss: 1.7673\n",
      "Epoch 9/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 74ms/step - accuracy: 0.8444 - loss: 0.2541 - val_accuracy: 0.6900 - val_loss: 1.5750\n",
      "Epoch 10/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 76ms/step - accuracy: 0.8430 - loss: 0.2534 - val_accuracy: 0.6895 - val_loss: 1.7565\n",
      "Epoch 11/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 76ms/step - accuracy: 0.8423 - loss: 0.2535 - val_accuracy: 0.6831 - val_loss: 1.8367\n",
      "Epoch 12/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 76ms/step - accuracy: 0.8408 - loss: 0.2519 - val_accuracy: 0.6890 - val_loss: 2.1604\n",
      "Epoch 13/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 76ms/step - accuracy: 0.8444 - loss: 0.2513 - val_accuracy: 0.6874 - val_loss: 1.6369\n",
      "Epoch 14/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 78ms/step - accuracy: 0.8441 - loss: 0.2504 - val_accuracy: 0.6858 - val_loss: 1.7344\n",
      "Epoch 15/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 78ms/step - accuracy: 0.8443 - loss: 0.2499 - val_accuracy: 0.6933 - val_loss: 2.2350\n",
      "Epoch 16/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 78ms/step - accuracy: 0.8419 - loss: 0.2503 - val_accuracy: 0.6918 - val_loss: 1.6343\n",
      "Epoch 17/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 79ms/step - accuracy: 0.8430 - loss: 0.2513 - val_accuracy: 0.6943 - val_loss: 2.4129\n",
      "Epoch 18/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 80ms/step - accuracy: 0.8425 - loss: 0.2520 - val_accuracy: 0.6897 - val_loss: 1.7887\n",
      "Epoch 19/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 80ms/step - accuracy: 0.8420 - loss: 0.2497 - val_accuracy: 0.6894 - val_loss: 1.6803\n",
      "Epoch 20/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 88ms/step - accuracy: 0.8416 - loss: 0.2497 - val_accuracy: 0.6924 - val_loss: 1.5820\n",
      "Epoch 21/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 90ms/step - accuracy: 0.8436 - loss: 0.2496 - val_accuracy: 0.6921 - val_loss: 1.8958\n",
      "Epoch 22/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 119ms/step - accuracy: 0.8414 - loss: 0.2505 - val_accuracy: 0.6911 - val_loss: 2.1887\n",
      "Epoch 23/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 164ms/step - accuracy: 0.8427 - loss: 0.2497 - val_accuracy: 0.6894 - val_loss: 1.2615\n",
      "Epoch 24/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 91ms/step - accuracy: 0.8430 - loss: 0.2492 - val_accuracy: 0.6912 - val_loss: 2.1794\n",
      "Epoch 25/25\n",
      "\u001b[1m2692/2692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 82ms/step - accuracy: 0.8431 - loss: 0.2492 - val_accuracy: 0.6906 - val_loss: 2.2242\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model.save('model.h5', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170/1170 [==============================] - 56s 48ms/step - loss: 0.6958 - accuracy: 0.4775\n",
      "Test Loss: 0.695849597454071\n",
      "Test Accuracy: 0.47752344608306885\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_set)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from  keras.models import load_model\n",
    "from keras.layers import DepthwiseConv2D\n",
    "\n",
    "loaded_model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m test_image \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.\u001b[39m  \u001b[38;5;66;03m# Normalize pixel values to [0, 1]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform prediction\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert the probability to a class label\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:  \u001b[38;5;66;03m# Threshold for binary classification\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\YASHPH~1\\AppData\\Local\\Temp\\__autograph_generated_fileoka6eynl.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the image and preprocess it\n",
    "image = cv2.imread('dataset/test_camera.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "invert = cv2.bitwise_not(gray)\n",
    "thresh = cv2.threshold(invert,130,255,cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite('inverted_image.jpg',thresh)\n",
    "test_image = tf.keras.utils.load_img('dataset/test-1.png', target_size=(64, 64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image /= 255.  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Perform prediction\n",
    "result = loaded_model.predict(test_image)\n",
    "\n",
    "# Convert the probability to a class label\n",
    "if result[0][0] > 0.5:  # Threshold for binary classification\n",
    "    prediction = 'Reversed'\n",
    "else:\n",
    "    prediction = 'Normal'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Reversal\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "# Load the image and preprocess it\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Perform thresholding on the image\n",
    "image = cv2.imread('dataset/test_camera.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save the thresholded image to disk\n",
    "cv2.imwrite('thresh_image.jpg', thresh)\n",
    "\n",
    "# Load the thresholded image directly as a numpy array\n",
    "test_image = cv2.imread('thresh_image.jpg')\n",
    "test_image = cv2.resize(test_image, (224, 224))\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "\n",
    "# Preprocess the image\n",
    "test_image = preprocess_input(test_image)\n",
    "\n",
    "# Perform prediction\n",
    "result = loaded_model.predict(test_image)\n",
    "\n",
    "# Convert the probability to a class label\n",
    "if result[0][0] > 0.5:\n",
    "    print(\"Reversal\")\n",
    "else:\n",
    "    print(\"Normal\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
